\chapter{Conclusions and Future Work}

The main objective of this project was to propose a framework which could be able to face the classification and temporally localization of activities on videos and submit the results to the ActivityNet Challenge 2016. The results obtained by the Neural Network proposed on this thesis to fulfill the goal are very good taking into account that was achieved from scratch. It can be consider that the main goal of this thesis has been accomplished.

Reaching this point though has not been a straight line but full of turns and dead ends. At first it was required to change the framework to use and port a whole model. This additional step gave the opportunity to share the process to the deep learning community which was warmly received. In addition to this, using information extracted from the audio tracks did not improve the performance as expected. To understand the reason, a qualitative exploration over the Dataset was done, concluding that in many videos the audio does not match the activity happening as there is music added after the recording.

Furthermore, a small bias has been observed at the results for both classification and temporally localization of activities. This bias affect the activities that are related to sports and movement activities which achieve better performance than the rest. This can be explained with the network used to extract the features from the frames, which was trained exclusively with sports videos. As this network was not fine-tuned for our data distribution, this bias appeared. As future work it can be possible to study the possibility to train the whole pipeline end to end to improve and get more uniformly distributed results.

It is also important to remark the good results achieved by a simple pipeline which from sequence of video frames predicts a sequence of depicted activities. Moreover, the flexibility of this sequence to sequence prediction allows the proposed network to face tasks where more than a single activity is present on a video. Recently it has been possible to compare the results with the other participants of the ActivityNet Challenge 2016 and it has been observed that the proposed network on this thesis obtain similar results than much more complicated approaches~\cite{singhmulti} and submissions of much more experienced researchers.

Finally, as future work, it may be interesting to use the optical flow as input as many state of the art publications propose~\cite{simonyan2014two,Ng_2015_CVPR,yao2015describing}. Another possible modification would be using a multi-stage architecture, predicting first whether there is an action or not, and if so, predict the activity class, as it is proposed in~\cite{shoutemporal}.
As a last idea for future work would be to pre-trained the Recurrent Neural Network to predict the next output from the current output. This technique is called semi-supervised and help to initialize a network when training with all your dataset and achieve improved results~\cite{harvey2015semi}.
All this ideas could also be tested with the Thumos dataset which, as ActivityNet, is made of untrimmed videos.

At last, all the code and models from this thesis to check and reproduce the results is publicly available on: \url{https://github.com/imatge-upc/activitynet-2016-cvprw}.
