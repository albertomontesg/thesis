\chapter*{Abstract}

This thesis explore different approaches using Convolutional and Recurrent Neural Networks to classify and temporally localize activities on videos, furthermore an implementation to achieve it has been proposed.

As the first step, features have been extracted from video frames using an state of the art 3D Convolutional Neural Network. This features are fed in a recurrent neural network that solves the activity classification and temporally location tasks in a simple and flexible way.

Different architectures and configurations have been tested in order to achieve the best performance and learning of the video dataset provided. In addition it has been studied different kind of post processing over the trained network's output to achieve a better results on the temporally localization of activities on the videos.

The results provided by the neural network developed in this thesis have been submitted to the ActivityNet Challenge 2016 of the CVPR, achieving competitive results using a simple and flexible architecture.
%Finally the results of this network have been submitted to the ActivityNet Challenge 2016 of the CVPR achieving competitive results with a simple and flexible architecture.

\chapter*{Resumen}

Esta tesis explora diferentes enfoques usando Redes Neuronales Convolucionales y Redes Neuronales Recurrentes para clasificar y localizar temporalmente actividades en videos y propone una implementación propia.

Como primer paso, se han extraido descriptores de videos usando Redes Neuronales Convolucionales 3D del estado del arte. Estos descriptores se introducen en una Red Neuronal Recurrente que resuelve la clasificación de actvidades y su localización temporal de una manera simple y flexible.

Diferentes arquitecturas y configuraciones se han testeado con el objetivo de conseguir el mejor resultado y aprendizaje del conjunto de vídeos subministrado. Además, se han estudiado diferentes tipos de post procesado sobre la salida de la red entrenada para conseguir mejores resultados en la localización de actividades en los vídeos.

Los resultados obtenidos por la red neuronal desarrollada en esta tesis han sido publicados en la ActivityNet Challenge 2016 del CVPR consiguiendo resultados competitivos con una simple y flexible arquitectura.
%Finalmente los resultados obtenidos por esta red entrenada se han publicado en la ActivityNet Challenge 2016 del CVPR consiguiendo resultados competitivos con una simple y flexible arquitectura.

\chapter*{Resum}

Aquesta tesis explora diferents enfocaments utilitzant Xarxes Neuronals Convolucionals i Xarxes Neuronals Recurrents per classificar i localitzar temporalment activitats en videos i proposa una implementació pròpia.

Com a primer pas, s'han extret descriptors de videos utilitzant Xarxes Neuronals Convolutionals 3D de l'estat de l'art. Aquests descriptors s'han introduït en una Xarxa Neuronal Recurren que resol la classificació d'activitats i la seva localització temporal d'una manera simple i flexible.

Diferents arquitectures i configuracions han estat testejades amb l'objectiu d'aconseguir el millor resultat i aprenentatge del conjunt de videos subministrats. A més, s'ha estudiat diferents tipus de post processat sobre la sortida de la xarxa entrenada per aconseguir els millors resultats en la localització d'activitats en els videos.

Els resultats obtinguts per la xarxa neuronal desenvolupada en aquesta tesis han estat publicats a la ActivityNet Challenge 2016 del CVPR aconseguint resultats competitius amb una simple i flexible arquitectura.
%Finalment els resultats obtinguts per aquesta xarxa entrenada s'han publicat a la ActivityNet Challenge 2016 del CVPR aconseguint resultats competitius amb una simple i flexible arquitectura.
