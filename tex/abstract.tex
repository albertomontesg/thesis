\chapter*{Abstract}

This thesis explore different approaches using Convolutional and Recurrent Neural Networks to classify and temporally localize activities on videos and propose an implementation to achieve it.

As the first step, features have been extracted from video frames using an state of the art 3D Convolutional Neural Network. Besides, it has been developed from scratch using the extracted features a neural network that tries to solve the activity classification and temporally location tasks in a simple and flexible way.

This neural network has been trained with different architectures and configurations in order to achieve the best performance and learning of the video dataset provided.

In addition it has been studied different kind of post processing over the trained network's output to achieve a better results on the temporally localization of activities on the videos.

Finally the results of this network has been submitted to the ActivityNet Challenge 2016 of the CVPR achieving interesting results with a simple and flexible architecture.

\chapter*{Resumen}

Esta tesis explora diferentes enfoques usando Redes Neuronales Convolucionales y Redes Neuronales Recurrentes para clasificar y localizar temporalmente actividades en videos y propone una implementación propia.

Como primer paso, se han extraido descriptores de videos usando Redes Neuronales Convolucionales 3D del estado del arte. Por otra parte, se ha desarrollado des de cero, usando los descriptores extraídos, una red neuronal que intenta resolver la clasificación de actvidades y su localización temporal de una manera simple y flexible.

Esta red neuronal se ha entrenado usando diferentes arquitecturas y configuraciones para conseguir el mejor resultado y aprendizaje del conjunto de vídeos subministrado. 

Además, se han estudiado diferentes tipos de post procesado sobre la salida de la red entrenada para conseguir mejores resultados en la localización de actividades en los vídeos.

Finalmente los resultados obtenidos por esta red entrenada se han publicado en la ActivityNet Challenge 2016 del CVPR consiguiendo interesantes resultados con una simple y flexible arquitectura.

\chapter*{Resum}

Aquesta tesis explora diferents enfocaments utilitzant Xarxes Neuronals Convolucionals y Xarxes Neuronals Recurrents per classificar i localitzar temporalment activitats en videos i proposa una implementació pròpia.

Com a primer pas, s'han extret descriptors de videos utilitzant Xarxes Neuronals Convolutionals 3D de l'estat de l'art. Per una altre banda, s'ha desenvolupat des de zero, utilitzant els descriptors extrets, una xarxa Neuronal que intenta resoldre la classificació d'activitats i la seva localització temporal d'una manera simple y flexible.

Aquesta xarxa neuronal ha estat entrenada utilitzant diferents arquitectures y configuracions per aconseguir el millor resultat y aprenentatge del conjunt de videos subministrats.

A més, s'ha estudiat diferents tipus de post processat sobre la sortida de la xarxa entrenada per aconseguir els millors resultats en la localització d'activitats en els videos.

Finalment els resultats obtinguts per aquesta xarxa entrenada s'han publicat a la ActivityNet Challenge 2016 del CVPR aconseguint interessant resultats amb una simple y flexible arquitectura.
